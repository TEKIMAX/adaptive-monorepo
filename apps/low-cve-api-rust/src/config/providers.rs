use crate::providers::{nvidia::NvidiaProvider, openai::OpenAIProvider, ollama::OllamaProvider, gemini::GeminiProvider};
use crate::traits::Provider;
use std::sync::Arc;

pub struct ProviderConfig {
    pub id: String,
    pub description: String,
    pub model_prefix: String,
    pub provider: Arc<dyn Provider>,
}

pub fn get_configured_providers() -> Vec<ProviderConfig> {
    vec![
        ProviderConfig {
            id: "openai".to_string(),
            description: "OpenAI GPT Models".to_string(),
            model_prefix: "gpt-".to_string(),
            provider: Arc::new(OpenAIProvider::new()),
        },
        ProviderConfig {
            id: "nvidia".to_string(),
            description: "NVIDIA NIM Microservices".to_string(),
            model_prefix: "nvidia".to_string(),
            provider: Arc::new(NvidiaProvider::new()),
        },
        ProviderConfig {
            id: "ollama".to_string(),
            description: "Ollama Local LLMs".to_string(),
            model_prefix: "ollama".to_string(),
            provider: Arc::new(OllamaProvider::new()),
        },
        ProviderConfig {
            id: "gemini".to_string(),
            description: "Google Gemini (via OpenAI Compat)".to_string(),
            model_prefix: "gemini".to_string(),
            provider: Arc::new(GeminiProvider::new()),
        },
    ]
}
