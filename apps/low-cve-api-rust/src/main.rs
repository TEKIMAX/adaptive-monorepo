use axum::{
    routing::{get, post},
    Router, Json, extract::State, response::{IntoResponse, Response, Sse},
    http::{StatusCode, HeaderMap},
};
use std::net::SocketAddr;
use std::sync::Arc;
use tower_http::cors::{CorsLayer, Any};
use dotenv::dotenv;
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};
use tokio::sync::mpsc;
use tokio_stream::wrappers::ReceiverStream;
use futures::StreamExt;
use axum::response::sse::{Event, KeepAlive};

mod config;
mod providers;
mod traits;
mod types;

use crate::config::providers::get_configured_providers;
use crate::types::{CreateResponseRequest, ListModelsResponse, OpenResponseEvent};

use utoipa::OpenApi;
use utoipa_swagger_ui::SwaggerUi;

#[derive(OpenApi)]
#[openapi(
    paths(
        health,
        list_models,
        create_response
    ),
    components(
        schemas(
            crate::types::CreateResponseRequest, 
            crate::types::InputItem, 
            crate::types::InputContent,
            crate::types::InputContentPart,
            crate::types::Tool,
            crate::types::GoogleSearchRetrieval,
            crate::types::FunctionDeclaration,
            crate::types::ListModelsResponse, 
            crate::types::Model,
            crate::types::OpenResponseEvent,
            crate::types::ResponseResource,
            crate::types::OpenResponseItem,
            crate::types::ErrorDetails
        )
    ),
    tags(
        (name = "adaptive-api-rust", description = "Adaptive Startup Rust API")
    )
)]
struct ApiDoc;

#[tokio::main]
async fn main() {
    dotenv().ok();
    
    tracing_subscriber::registry()
        .with(tracing_subscriber::EnvFilter::new(
            std::env::var("RUST_LOG").unwrap_or_else(|_| "info".into()),
        ))
        .with(tracing_subscriber::fmt::layer())
        .init();

    // CORS
    let cors = CorsLayer::new()
        .allow_origin(Any)
        .allow_methods(Any)
        .allow_headers(Any);

    let app = Router::new()
        .route("/", get(root))
        .route("/health", get(health))
        .route("/v1/models", get(list_models))
        .route("/v1/responses", post(create_response))
        .merge(SwaggerUi::new("/docs").url("/api-docs/openapi.json", ApiDoc::openapi()))
        .layer(cors);

    let port = std::env::var("PORT").unwrap_or_else(|_| "8080".to_string()).parse::<u16>().unwrap();
    let addr = SocketAddr::from(([0, 0, 0, 0], port));
    tracing::info!("listening on {}", addr);
    
    let listener = tokio::net::TcpListener::bind(&addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}

async fn root() -> &'static str {
    "Adaptive API Rust (Axum Container) is Running"
}

#[utoipa::path(
    get,
    path = "/health",
    responses(
        (status = 200, description = "Health check passed", body = String)
    )
)]
async fn health() -> &'static str {
    "OK"
}

#[utoipa::path(
    get,
    path = "/v1/models",
    responses(
        (status = 200, description = "List available models", body = ListModelsResponse)
    )
)]
async fn list_models() -> Json<ListModelsResponse> {
    let providers = get_configured_providers();
    let mut all_models = Vec::new();
    
    for config in providers {
        match config.provider.list_models().await {
            Ok(models) => all_models.extend(models),
            Err(e) => tracing::error!("Provider {} list_models failed: {}", config.id, e),
        }
    }
    
    Json(ListModelsResponse {
        object: "list".to_string(),
        data: all_models,
    })
}

#[utoipa::path(
    post,
    path = "/v1/responses",
    request_body = CreateResponseRequest,
    responses(
        (status = 200, description = "Streamed AI response", body = String)
    )
)]
async fn create_response(
    headers: HeaderMap,
    Json(payload): Json<CreateResponseRequest>,
) ->  impl IntoResponse {
    handle_response_logic(headers, payload).await
}

async fn handle_response_logic(
    headers: HeaderMap,
    payload: CreateResponseRequest,
) -> impl IntoResponse {
    let providers = get_configured_providers();
    
    // Find provider based on model prefix
    let provider_config = providers.iter()
        .find(|p| payload.model.starts_with(&p.model_prefix));

    let provider = match provider_config {
        Some(p) => p.provider.clone(),
        None => return (StatusCode::NOT_FOUND, "Provider not found for model").into_response(),
    };

    // Create channel
    let (tx, rx) = mpsc::channel(100);
    
    // Spawn execution
    let payload_clone = payload;
    let headers_clone = headers.clone();
    
    tokio::spawn(async move {
        // Trigger execution
        if let Err(e) = provider.execute(&payload_clone, &headers_clone, tx.clone()).await {
             let _ = tx.send(OpenResponseEvent::Error { 
                 error: crate::types::ErrorDetails { 
                     code: "internal_error".to_string(), 
                     message: e.to_string() 
                 }
             }).await;
        }
    });

    // Convert Receiver to Stream of SSE Events
    let stream = ReceiverStream::new(rx).map(|event| {
        let json = serde_json::to_string(&event).unwrap_or_default();
        match event {
             OpenResponseEvent::Error { .. } => Ok::<Event, std::convert::Infallible>(Event::default().event("error").data(json)),
             _ => Ok::<Event, std::convert::Infallible>(Event::default().data(json))
        }
    });

    Sse::new(stream).keep_alive(KeepAlive::default()).into_response()
}
